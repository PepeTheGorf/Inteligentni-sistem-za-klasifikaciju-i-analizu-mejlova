{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f1c0481",
   "metadata": {},
   "source": [
    "# Sistem za klasifikaciju email-ova\n",
    "\n",
    "## Uvod\n",
    "\n",
    "Ovaj notebook prikazuje dva pristupa klasifikaciji e-mail poruka na **spam** i **ham**:\n",
    "\n",
    "1. **Klasični pristup (Bag-of-Words + Naive Bayes)**\n",
    "   - Čišćenje i normalizacija teksta\n",
    "   - Numerička reprezentacija pomoću BoW\n",
    "   - Trening jednostavnog Naive Bayes modela\n",
    "   - Evaluacija modela: Accuracy, Precision, Recall, F1-score, Precision Matrix\n",
    "   - Opcionalno balansiranje klasa sa SMOTE\n",
    "\n",
    "2. **Napredni pristup (BERT Transformer)**\n",
    "   - Korišćenje unapred treniranog BERT modela (DistilBERT-a. RoBERTa, BERT-Base)\n",
    "   - Fine-tuning BERT-a na našem dataset-u za klasifikaciju spam/ham\n",
    "   - Evaluacija performansi na test skupu\n",
    "   - Upoređivanje rezultata sa Naive Bayes klasifikatorom\n",
    "\n",
    "**Cilj:** Demonstrirati razliku između klasičnog modela i moćnog modernog NLP transformera, kao i razumeti prednosti BERT-a kod tekstualnih klasifikacija."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb83dd",
   "metadata": {},
   "source": [
    "## Klasifikaciju pomoću Naive Bayes-a\n",
    "\n",
    "### Biblioteke\n",
    "\n",
    "Uvoz potrebnih biblioteka za obradu podataka, metrike, balansiranje klasa i vizualizaciju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012537e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1672b",
   "metadata": {},
   "source": [
    "## Čišćenje i priprema teksta\n",
    "\n",
    "- **`clean_text`**: normalizuje tekst (mala slova, uklanja \"Subject:\", linkove, brojeve, specijalne karaktere i višestruke razmake).  \n",
    "- **`load_datasets`**: učitava Enron i Venky dataset, primenjuje `clean_text` i pretvara label-e u numeričke vrijednosti (`0`=ham, `1`=spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f13be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting text\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"subject:\", \"\", text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "#preparing dataset\n",
    "def load_datasets():\n",
    "    df_enron = pd.read_csv(\"../data/enron_mails.csv\").dropna(subset=[\"Message\"])\n",
    "    df_venky = pd.read_csv(\"../data/venky_spam_ham_dataset.csv\").dropna(subset=[\"text\"])\n",
    "\n",
    "    df_enron[\"full_text\"] = (\n",
    "        df_enron[\"Subject\"].fillna(\"\") + \" \" + df_enron[\"Message\"].fillna(\"\")\n",
    "    ).apply(clean_text)\n",
    "    df_venky[\"text\"] = df_venky[\"text\"].apply(clean_text)\n",
    "\n",
    "    df_enron[\"label_num\"] = df_enron[\"Spam/Ham\"].map({\"ham\": 0, \"spam\": 1})\n",
    "    df_venky[\"label_num\"] = df_venky[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "    return df_enron, df_venky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0dfc61",
   "metadata": {},
   "source": [
    "## Balansiranje klasa sa SMOTE\n",
    "\n",
    "- **`apply_smote`**: primenjuje SMOTE za balansiranje neuravnoteženih klasa.  \n",
    "- Prikazuje raspodelu klasa pre i posle resamplovanja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6126bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X_bow, y):\n",
    "    print(f\"\\nOriginal class distribution: {Counter(y)}\")\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_bow, y)\n",
    "\n",
    "    print(f\"Resampled class distribution: {Counter(y_resampled)}\")\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c253a",
   "metadata": {},
   "source": [
    "## Bag-of-Words (BoW)\n",
    "\n",
    "- **`SimpleBoW`**: pretvara tekst u numeričke vektore po principu Bag-of-Words.  \n",
    "- **`fit`**: kreira rečnik svih reči iz dokumenata.  \n",
    "- **`transform`**: svaki dokument pretvara u vektor broja pojavljivanja reči.  \n",
    "- **`fit_transform`**: kombinuje `fit` i `transform` u jednoj funkciji.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93346ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBoW:\n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "\n",
    "    def fit(self, documents):\n",
    "        vocab_set = set()\n",
    "        for doc in documents:\n",
    "            for word in doc.split():\n",
    "                vocab_set.add(word)\n",
    "        self.vocab = {word: i for i, word in enumerate(sorted(vocab_set))}\n",
    "\n",
    "    def transform(self, documents):\n",
    "        n_docs = len(documents)\n",
    "        n_vocab = len(self.vocab)\n",
    "        matrix = np.zeros((n_docs, n_vocab), dtype=np.float32)\n",
    "        for i, doc in enumerate(documents):\n",
    "            for word in doc.split():\n",
    "                if word in self.vocab:\n",
    "                    matrix[i, self.vocab[word]] += 1\n",
    "        return matrix\n",
    "\n",
    "    def fit_transform(self, documents):\n",
    "        self.fit(documents)\n",
    "        return self.transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c39ee0",
   "metadata": {},
   "source": [
    "## Simple Naive Bayes - Lepa verzija\n",
    "\n",
    "Ova klasa implementira **Multinomial Naive Bayes** za klasifikaciju teksta (spam/ham).\n",
    "\n",
    "\n",
    "### 1. Naive Bayes formula\n",
    "\n",
    "Cilj je odrediti kojoj klasi $(c)$ pripada dokument:\n",
    "\n",
    "$$\n",
    "P(c \\mid \\text{dokument}) \\propto P(c) \\times \\prod_{i=1}^{n} P(w_i \\mid c)^{x_i}\n",
    "$$\n",
    "\n",
    "> **Objašnjenje:**  \n",
    "> - $P(c)$ = prior klase  \n",
    "> - $P(w_i \\mid c)$ = verovatnoća reči $w_i$ u toj klasi  \n",
    "> - $x_i$ = broj pojavljivanja reči u dokumentu  \n",
    "> - Verovatnoća klase je proporcionalna prioru klase i proizvodu verovatnoća svih reči u dokumentu\n",
    "\n",
    "\n",
    "### 2. Laplace smoothing\n",
    "\n",
    "Dodajemo 1 da izbegnemo verovatnoće 0:\n",
    "\n",
    "$$\n",
    "P(w_i \\mid c) = \\frac{\\text{count}(w_i, c) + 1}{\\text{ukupan broj reči u klasi} + |V|}\n",
    "$$\n",
    "\n",
    "> **Objašnjenje:**  \n",
    "> - $(|V|)$ = veličina vokabulara  \n",
    "> - Laplace smoothing osigurava da nijedna reč ne daje verovatnoću 0, što bi uništilo izračunavanje posteriora.\n",
    "\n",
    "\n",
    "### 3. Logaritmovanje\n",
    "\n",
    "Proizvod malih verovatnoća može dovesti do **numerical underflow**, pa koristimo log:\n",
    "\n",
    "$$\\log(ab) = \\log a + \\log b$$\n",
    "\n",
    "$$\n",
    "\\log P(c \\mid \\text{dokument}) = \\log P(c) + \\sum_{i=1}^{n} x_i \\log P(w_i \\mid c)\n",
    "$$\n",
    "\n",
    "> **Objašnjenje:**  \n",
    "> - Sabiranjem logova dobijamo isti rezultat kao proizvod, ali numerički stabilnije  \n",
    "> - $(x_i \\cdot \\log P(w_i \\mid c))$ → doprinos svake reči pomnožen sa brojem pojavljivanja  \n",
    "> - Logaritmom pretvaramo proizvod verovatnoća u sumu, što omogućava “sabiranje dokaza” svake reči za klasu.\n",
    "\n",
    "\n",
    "### 4. Predikcija\n",
    "\n",
    "Za svaki dokument računamo log-score po klasama i biramo klasu sa najvećim score-om:\n",
    "\n",
    "$$\n",
    "\\text{pred} = \\arg\\max_c \\Big( \\log P(c) + \\sum_{i=1}^{n} x_i \\log P(w_i \\mid c) \\Big)\n",
    "$$\n",
    "\n",
    "> **Objašnjenje:**  \n",
    "> - Rezultat je 0 ili 1 (ham/spam)  \n",
    "> - Funkcija `max` bira klasu koja je najverovatnija s obzirom na sadržaj dokumenta  \n",
    "> - Logaritmovanje i sabiranje omogućava da se sabere doprinos svake reči za klasu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_word_probs = {}\n",
    "        self.class_priors = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_docs, n_words = X.shape\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        for c in classes:\n",
    "            #getting documents of class\n",
    "            X_c = X[y == c]\n",
    "            word_counts = X_c.sum(axis=0)\n",
    "            total_words = word_counts.sum()\n",
    "\n",
    "            #laplace smoothing\n",
    "            probs = (word_counts + 1) / (total_words + n_words) #likelihood of word appearing in class\n",
    "            self.class_word_probs[c] = probs\n",
    "            self.class_priors[c] = X_c.shape[0] / n_docs    #likelihood of being that class\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        #for document\n",
    "        for x in X:\n",
    "            scores = {}\n",
    "            #for each class\n",
    "            for c in self.class_word_probs:\n",
    "                log_prob = np.log(self.class_priors[c])\n",
    "                log_prob += np.sum(x * np.log(self.class_word_probs[c]))\n",
    "                scores[c] = log_prob\n",
    "            pred = max(scores, key=scores.get)\n",
    "            results.append(pred)\n",
    "        return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037070a",
   "metadata": {},
   "source": [
    "## Funkcije za treniranje i evaluaciju modela\n",
    "\n",
    "Ovaj deo koda omogućava treniranje Naive Bayes modela na tekstualnim dataset-ovima i evaluaciju njegovih performansi.\n",
    "\n",
    "\n",
    "### Funkcija `evaluate_model`\n",
    "\n",
    "- Prima stvarne vrednosti `y_true` i predikcije modela `y_pred`.\n",
    "- Računa **standardne metrike klasifikacije**:  \n",
    "  - **Accuracy** – udeo tačno klasifikovanih primera  \n",
    "  - **Precision** – koliko su pozitivne predikcije tačne  \n",
    "  - **Recall** – koliko stvarnih pozitivnih primera model pravilno detektuje  \n",
    "  - **F1-score** – harmonijska sredina precision i recall  \n",
    "- Prikazuje **confusion matrix** radi vizualnog uvida u greške i tačne klasifikacije.\n",
    "\n",
    "\n",
    "### Funkcija `train_and_evaluate`\n",
    "\n",
    "- Omogućava dva režima treniranja:  \n",
    "  1. **Cross-dataset (`cross`)** – trenira se na Enron ili Venky i testira na drugom dataset-u  \n",
    "  2. **Split (`split`)** – standardna podela 80/20 unutar Enron dataset-a  \n",
    "- Koristi **Bag-of-Words** za transformaciju teksta u numerički format.  \n",
    "- Opcionalno primenjuje **SMOTE** za balansiranje klasa.  \n",
    "- Trening i predikcija se rade preko `SimpleNaiveBayes` klase.  \n",
    "- Rezultati se evaluiraju pomoću funkcije `evaluate_model`, koja prikazuje metrike i matricu konfuzije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate(train_enron=1, use_smote=False, mode=\"cross\"):\n",
    "    df_enron, df_venky = load_datasets()\n",
    "\n",
    "    if mode == \"cross\":\n",
    "        if train_enron == 1:\n",
    "            X_train = df_enron[\"full_text\"]\n",
    "            y_train = df_enron[\"label_num\"].to_numpy()\n",
    "            X_test = df_venky[\"text\"]\n",
    "            y_test = df_venky[\"label_num\"].to_numpy()\n",
    "            print(\"\\nTraining on Enron, Testing on Venky\")\n",
    "        else:\n",
    "            X_train = df_venky[\"text\"]\n",
    "            y_train = df_venky[\"label_num\"].to_numpy()\n",
    "            X_test = df_enron[\"full_text\"]\n",
    "            y_test = df_enron[\"label_num\"].to_numpy()\n",
    "            print(\"\\nTraining on Venky, Testing on Enron\")\n",
    "\n",
    "    elif mode == \"split\":\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        #enron 80/20 split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_enron[\"full_text\"], df_enron[\"label_num\"].to_numpy(),\n",
    "            test_size=0.2, random_state=42, stratify=df_enron[\"label_num\"]\n",
    "        )\n",
    "        print(\"\\nTraining on 80% and testing on 20% of Enron\")\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'cross' or 'split'\")\n",
    "\n",
    "    bow = SimpleBoW()\n",
    "    X_train_bow = bow.fit_transform(X_train)\n",
    "    X_test_bow = bow.transform(X_test)\n",
    "\n",
    "    if use_smote:\n",
    "        X_train_bow, y_train = apply_smote(X_train_bow, y_train)\n",
    "\n",
    "    nb = SimpleNaiveBayes()\n",
    "    nb.fit(X_train_bow, y_train)\n",
    "\n",
    "    y_pred = nb.predict(X_test_bow)\n",
    "    evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd3227",
   "metadata": {},
   "source": [
    "## Zaključak i pokretanje glavnog dela koda\n",
    "\n",
    "Kroz ove tri konfiguracije možemo uporediti kako Naive Bayes model radi u različitim scenarijima i uticaj SMOTE balansiranja na rezultate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Cross WITHOUT SMOTE\")\n",
    "    print(\"=\" * 50)\n",
    "    train_and_evaluate(train_enron=0, use_smote=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Cross WITH SMOTE\")\n",
    "    print(\"=\" * 50)\n",
    "    train_and_evaluate(train_enron=0, use_smote=True)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Standard WITHOUT SMOTE\")\n",
    "    print(\"=\" * 50)\n",
    "    train_and_evaluate(train_enron=0, use_smote=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
